mean(mean.cont)
mean(data)
data
s.data = read.table("Seattle.txt", header = T)
length(data)
B = 10000
mean.cont = NULL
for(b in 1:B) {
resample = sample(data, 72, replace = T)
mean.cont[b] = mean(resample)
}
mean.cont
mean(data) - mean(mean.cont)
s.data = read.table("Seattle.txt", header = T)
?t.test()
t.test(s.data$X2001, s.data$X2002, alternative = c("two.sided"))
two1 = s.data$X2001
two2 = s.data$X2002
type = c(rep(0, times = length(two1), 1, times = length(two2, times = length(two2)))
type = c(rep(0, times = length(two1), rep(1, times = length(two2, times = length(two2))))
type.vec = c(rep(0, times = length(two1), rep(1, times = length(two2, times = length(two2))))
type.vec = c(rep(0, times = length(two1)), rep(1, times = length(two2)))
type.vec = c(rep(0, times = length(two1)), rep(1, times = length(two2)))
type.vec
first.obs = mean(two1) - mean(two2)
first.obs
total.data = c(two1, two2)
two1 = s.data$X2001
two2 = s.data$X2002
total.data = c(two1, two2)
type.vec = c(rep(0, times = length(two1)), rep(1, times = length(two2)))
first.obs = mean(two1) - mean(two2)
first.obs
I = 10000
perm.mean = NULL
for(i in 1:I) {
resample = sample(type.vec, length(type.vec),replace = F)
perm.mean[i] = mean(total.data[type == 0]) - mean(total.data[type == 1])
}
two1 = s.data$X2001
two2 = s.data$X2002
total.data = c(two1, two2)
type.vec = c(rep(0, times = length(two1)), rep(1, times = length(two2)))
first.obs = mean(two1) - mean(two2)
first.obs
I = 10000
perm.mean = NULL
for(i in 1:I) {
resample = sample(type.vec, length(type.vec),replace = F)
perm.mean[i] = mean(total.data[type.vec == 0]) - mean(total.data[type.vec == 1])
}
1/I * sum( which(perm.mean > first.obs)   )
library(rnoaa)
?ncdc
stations <- c(720545, 725027, 725029, 725040, 725045, 725046, 725080, 725084, 725086, 997283, 997284, 997290)
met.data <- ncdc(datasetid = 'GHCND', stationid = stations, startdate = '07-21-2017', enddate = '07-21-2017')
options(noaakey = "guBcJPsbWZRtARjyhoqmsTjIAAZFoDkj")
met.data <- ncdc(datasetid = 'GHCND', stationid = stations, startdate = '07-21-2017', enddate = '07-21-2017')
met.data <- ncdc(datasetid = 'GHCND', stationid = stations, startdate = '2017-07-21', enddate = '2017-07-21')
met.data <- ncdc(datasetid = 'GHCND', stationid = stations, startdate = '2017-07-21', enddate = '2017-07-22')
met.data <- ncdc(datasetid = 'GHCND', stationid = stations, startdate = '2017-07-21', enddate = '2017-07-22')
met.data <- ncdc(datasetid = 'GHCND', locationid = stations, startdate = '2017-07-21', enddate = '2017-07-22')
stationsWBAN <- c(99999, 54788, 64707, 94702, 14758, 14707, 14740, 54767, 54734, 99999, 99999, 99999)
met.data <- ncdc(datasetid = 'GHCND', locationid = stationsWBAN, startdate = '2017-07-21', enddate = '2017-07-22')
met.data <- ncdc(datasetid = 'GHCND', startdate = '2017-07-21', enddate = '2017-07-21')
met.data$meta
met.data <- ncdc(datasetid = 'GHCND',stationid = 54788 startdate = '2017-07-21', enddate = '2017-07-21')
met.data <- ncdc(datasetid = 'GHCND',stationid = 54788, startdate = '2017-07-21', enddate = '2017-07-21')
library(polMod)
knitr::opts_chunk$set(echo = TRUE)
EoE <- abs(pop.hi.mean - y.bar)
statvil <- read.table("data1991.txt", header=F,
colClasses=c(rep(NA,3), "character", rep(NA,32)))
colnames(statvil) <- c("block", "unit", "hhsize", "hhtemp",
"nuempinh", "nuirh", "empinch", "invsth", "govinch", "otinch", "totinch",
"dtypeh", "builth", "tenurh", "morgh", "roomh", "broomh", "valueh", "grosrth", "omph",
"hmage", "hmsex", "hmmtn", "hmhlos", "hmocc91", "hmlfact", "hmwkswk", "hmempin",
"shmage", "shmsex", "shmmtn", "shmhlos", "shmocc91", "shmlfact", "shmwkswk", "shmempin")
hhper <- c("hhpera", "hhperb1", "hhperb2", "hhperd1",
"hhperd2", "hhpere1", "hhpere2", "hhperf1", "hhperf2", "hhperg1", "hhperg2", "hhperh1", "hhperh2")
for(i in 1:length(hhper)){
assign(hhper[i], substr(statvil$hhtemp, i,i))
foo <- colnames(statvil)
statvil <- cbind(statvil, get(hhper[i]))
colnames(statvil) <- c(foo, hhper[i])
}
statvil <- statvil[ , - which(colnames(statvil) == "hhtemp")]
rm(list=c("hhpera", "hhperb1", "hhperb2", "hhperd1",
"hhperd2", "hhpere1", "hhpere2", "hhperf1", "hhperf2", "hhperg1", "hhperg2", "hhperh1", "hhperh2"))
pop.house.income <- statvil$totinch
pop.hi.mean <- round(mean(pop.house.income, na.rm = TRUE), 2)
pop.hi.median <- round(median(pop.house.income, na.rm = TRUE), 2)
pop.hi.sd <- round(sd(pop.house.income, na.rm = TRUE), 2)
pop.hi.iqr <- round(IQR(pop.house.income, na.rm = TRUE), 2)
pop.hi.mean
pop.hi.median
pop.hi.sd
pop.hi.iqr
hist(pop.house.income, breaks=50, col="orange", probability=TRUE,
main="Total Population Household Income", xlab="Values")
curve(expr=dnorm(x, mean=mean(pop.house.income), sd=sd(pop.house.income)), from=0, to=4, add=TRUE)
n = 80
y.bar.var <- var(pop.house.income) / n
y.bar.se <- sqrt(y.bar.var)
y.bar.se
set.seed(12345)
my.sample.rows <- sample(1024, size=80, replace=FALSE)
sample80 <- statvil[my.sample.rows, ]
library(survey)
fpc.srs <- rep(1024, 80)
my.design <- svydesign(id=~1, strata=NULL, data=sample80, fpc=fpc.srs)
svymean(x=~totinch, design=my.design)
n = 80
N = 1024
n/N
y.bar <- round(mean(sample80$totinch), 2)
s <- round(sd(sample80$totinch), 2)
sigma.hat.squared <- (N - 1) / (N) * s^2 * (1/n) * (N - n)/ (n - 1)
sigma.hat <- sqrt(sigma.hat.squared)
y.bar
svymean(x=~totinch, design=my.design)
sigma.hat
str(svymean(x=~totinch, design=my.design))
svymean(x=~totinch, design=my.design)
EoE <- abs(pop.hi.mean - y.bar)
EoE
bound <- 2 * sigma.hat
bound
EoE
EoE < bound
?sample
SE(svymean(x=~totinch, design=my.design))
svymean(x=~totinch, design=my.design)
SE(svymean(x=~totinch, design=my.design))
set.seed(12345)
runs = 50       # Declare the number of repetitions
samp.size <- 80 # Declare the sample size
all.means <- NULL
lower.conf.ints <- NULL
upper.conf.ints <- NULL
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample <- sample(pop.house.income, samp.size, replace = TRUE)
# Tell R the study design for our sample
my.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=fpc.srs)
# Calculate sample mean and SE
svymean(x=~pop.house.income, design=my.design)
my.mean <- svymean(x=~pop.house.income, design=my.design)[1]
my.SE <- round(SE(svymean(x=~pop.house.income, design=my.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
?svydesign
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample <- sample(pop.house.income, samp.size, replace = TRUE)
# Tell R the study design for our sample
my.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=NULL)
# Calculate sample mean and SE
svymean(x=~totinch, design=my.design)
my.mean <- svymean(x=~totinch, design=my.design)[1]
my.SE <- round(SE(svymean(x=~totinch, design=my.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample.rows <- sample(1024, samp.size, replace = TRUE)
new.sample <- statvil[new.sample.rows,]
# Tell R the study design for our sample
my.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=NULL)
# Calculate sample mean and SE
svymean(x=~totinch, design=my.design)
my.mean <- svymean(x=~totinch, design=my.design)[1]
my.SE <- round(SE(svymean(x=~totinch, design=my.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
library(plotrix)
install.packages("plotrix")
library(plotrix)
plot(x=1,y=1, main="Confidence Intervals for Income", xlab="Income", ylab="Sample",
xlim=c(min(lower.conf.ints), max(upper.conf.ints)),
ylim=c(0,55))
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
for(i in 1:50){
plotCI(x=all.means[i], y=i,
ui=upper.conf.ints[i], li=lower.conf.ints[i],
sfrac=0.005, err="x", add=TRUE, cex=0.3)
}
plot(x=1,y=1, main="Confidence Intervals for Income", xlab="Income", ylab="Sample",
xlim=c(min(lower.conf.ints), max(upper.conf.ints)),
ylim=c(0,55))
# Add a reference line for true population mean
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
# Plot 50 confidence intervals
for(i in 1:50){
plotCI(x=all.means[i], y=i,
ui=upper.conf.ints[i], li=lower.conf.ints[i],
sfrac=0.005, err="x", add=TRUE, cex=0.3)
}
library(plotrix)
# Set up an empty plot first, with the relevant limits for x and y axes
plot(x=1,y=1, main="Confidence Intervals for Income", xlab="Income", ylab="Sample",
xlim=c(min(lower.conf.ints), max(upper.conf.ints)),
ylim=c(0,55))
# Add a reference line for true population mean
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
# Plot 50 confidence intervals
for(i in 1:50){
plotCI(x=all.means[i], y=i,
ui=upper.conf.ints[i], li=lower.conf.ints[i],
sfrac=0.005, err="x", add=TRUE, cex=0.3)
}
```{r}
set.seed(12345)
runs = 50       # Declare the number of repetitions
samp.size <- 80 # Declare the sample size
all.means <- NULL
lower.conf.ints <- NULL
upper.conf.ints <- NULL
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample.rows <- sample(1024, samp.size, replace = TRUE)
new.sample <- statvil[new.sample.rows,]
# Tell R the study design for our sample
new.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=NULL, weights = NULL)
# Calculate sample mean and SE
svymean(x=~totinch, design=new.design)
my.mean <- svymean(x=~totinch, design=new.design)[1]
my.SE <- round(SE(svymean(x=~totinch, design=new.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
curve(expr=dnorm(x, mean=mean(pop.house.income, na.rm = TRUE), sd=sd(pop.house.income, na.rm = TRUE)), from=0, to=4, add=TRUE)
hist(pop.house.income, breaks=50, col="orange", probability=TRUE,
main="Total Population Household Income", xlab="Values")
m <- mean(pop.house.income)
std <- sd(pop.house.income)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(statvil$totinch, breaks=50, col="orange", probability=TRUE,
main="Total Population Household Income", xlab="Values")
m <- mean(pop.house.income)
std <- sd(pop.house.income)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(statvil$totinch, breaks=50, col="orange", probability=TRUE, density = 20,
main="Total Population Household Income", xlab="Values")
m <- mean(pop.house.income)
std <- sd(pop.house.income)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
curve(dnorm(statvil$totinch, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
library(polMod)
knitr::opts_chunk$set(echo = TRUE)
proc <- as.factor(rep(c(1,1,1,1, 2,2,2,2, 3,3,3,3), 3))
bat <- as.factor(rep(c(1,2,3,4, 1,2,3,4, 1,2,3,4), 3))
bur <- c(25, 19, 15, 15, 19, 23, 18, 35, 14, 35, 38, 25,
30, 28, 17, 16, 17, 24, 21, 27, 15, 21, 54, 29,
26, 20, 14, 13, 14, 21, 17, 25, 20, 24, 50, 33)
burn.d <- data.frame(proc, bat, bur)
library(lmer)
library(lme4)
library(lmerTest)
burn.m <- lmer(bur ~ proc + (1|bat), data = burn.d)
summary(burn.m)
burn.m.red.one <-  lmer(bur ~ proc, data = burn.d)
burn.m.red.one <-  aov(bur ~ proc, data = burn.d)
anova(burn.m, burn.m.red.one)
anova(burn.m.red.one)
library(agricolae)
burn.Tukey <- HSD.test(burn.m.red.one, "proc", group = TRUE)
burn.T
burn.Tukey
burn.res <- burn.m.red.one$residuals
burn.fit <- burn.m.red.one$fitted.values
qqnorm(burn.res)
burn.res.d <- data.frame(burn.res, burn.fit)
ggplot(burn.res.d, aes(x=burn.fit, y=burn.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
library(ggplot2)
ggplot(burn.res.d, aes(x=burn.fit, y=burn.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(lmerTest)
library(agricolae)
library(ggplot2)
semiconductor <- data.frame(resistance = c(5.22, 	5.6, 	5.78, 	5.57, 	5.66, 	6.23, 	6.75, 	6.12, 	5.61, 	5.91, 	6.52, 	5.96, 	6.25, 	6.84, 	6.97, 	6.61, 	6.11, 	5.49, 	5.9, 	6.43, 	5.46, 	6.22, 	6.02, 	6.05, 	6.33, 	4.6, 	5.67, 	5.81, 	5.08, 	6.29, 	6.88, 	6.15, 	6.13, 	4.95, 	5.77, 	5.83, 	6.53, 	5.63, 	6.22, 	5.55, 	6.14, 	5.42, 	6.23, 	6.12, 	6.5, 	6.36, 	6.54, 	6.13),
et = as.factor(c(1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4)),
wafer = as.factor(c(1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3)),
pos = as.factor(c(1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	2, 	4, 	2, 	4, 	2, 	4, 	2, 	4, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	4, 	2, 	4, 	2, 	4, 	2, 	4, 	2, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	2, 	4, 	2, 	4, 	2, 	4, 	2, 	4))
)
resistance.m <- lmer(resistance ~ et + pos + (1|et:wafer),data = semiconductor)
summary(resistance.m)
resistance.m.one <- lmer(resistance ~ et + pos, data = semiconductor)
resistance.m.one <- lm(resistance ~ et + pos, data = semiconductor)
anova(resistance.m, resistance.m.one)
anova(resistance.m.one)
et.tukey <- HSD.test(resistance.m.one)
et.tukey <- HSD.test(resistance.m.one, "resistance", group = TRUE)
et.tukey
et.tukey <- HSD.test(resistance.m.one, "et", group = TRUE)
et.tukey
resistance.res <- resistance.m.one$residuals
resistance.fit <- resistance.m.one$fitted.values
resistance.res.d <- data.frame(resistance.res, resistance.fi)
resistance.res.d <- data.frame(resistance.res, resistance.fit)
qqnrom(resistance.res)
qqnorm(resistance.res)
ggplot(resistance.res.d, aes(x=resistance.fit, y=resistance.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
summary(resistance.m)
anova(resistance.m)
resistance.m.one <- lm(resistance ~ et + pos, data = semiconductor)
anova(resistance.m, resistance.m.one)
resistance.m <- lmer(resistance ~ et + pos + (1|et:wafer),data = semiconductor)
resistance.m.one <- lm(resistance ~ et + pos, data = semiconductor)
anova(resistance.m, resistance.m.one)
anova(resistance.m)
pos.tukey <- HSD.test(resistance.m.one, "pos", group = TRUE)
pos.tukey
pos.tukey <- HSD.test(resistance.m, "pos", group = TRUE)
pos.tukey <- HSD.test(resistance.m, "pos", group = TRUE)
resistance.res <- resistance.m$residuals
resistance.fit <- resistance.m$fitted.values
resistance.res <- resid(resistance.m)
resistance.fit <- fitted(resistance.m)
resistance.res.d <- data.frame(resistance.res, resistance.fit)
qqnorm(resistance.res)
lsmeans::lsmeans(resistance.m, pairwise~pos, adjust=c("tukey"))
lsmeans::lsmeans(resistance.m, pairwise~et, adjust=c("tukey"))
lsmeans::lsmeans(resistance.m, pairwise~pos, adjust=c("tukey"))
job <- as.factor(c(rep(1, 6), rep(2,6), rep(3,6), rep(4,6), rep(5,6), rep(6,6)))
oper <- as.factor(rep(c(1,1,2,2,3,3), 6))
time <- c(158.3, 159.4, 159.2, 159.6, 158.9, 157.8,
154.6, 154.9, 157.7, 156.8, 154.8, 156.3,
162.5, 162.6, 161.0, 158.9, 160.5, 159.5,
160.0, 158.7, 157.5, 158.9, 161.1, 158.5,
156.3, 158.1, 158.3, 156.9, 157.7, 156.9,
163.7, 161.0, 162.3, 160.3, 162.6, 161.8)
job.d <- data.frame(job, oper, time)
library(lme4)
library(lmerTest)
library(agricolae)
library(ggplot2)
job.m <- lmer(time ~ oper + (1|oper) + (1|oper:job) , data = job.d)
job.m.two <- lmer(time ~ oper + (1|oper), data = job.d)
job.m <- lmer(time ~ oper + (1|job) + (1|oper:job) , data = job.d)
job.m.two <- lmer(time ~ oper + (1|job), data = job.d)
anova(job.m, job.m.two)
job.m.three <- lm(time ~ oper, data = job.d)
anova(job.m.two, job.m.three)
summary(job.m.two)
anova(job.m.three)
job.res <- resid(job.m.two)
job.fit <- fitted(job.m.two)
job.res.d <- data.frame(job.res, job.fit)
qqnorm(job.res)
ggplot(job.res.d, aes(x=job.fit, y=job.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
mean(job.d$time)
job.m <- lmer(time ~ oper + (1|job:oper), data = job.d)
library(lme4)
library(lme4)
library(lmerTest)
library(agricolae)
library(ggplot2)
job.m <- lmer(time ~ oper + (1|job:oper), data = job.d)
job <- as.factor(c(rep(1, 6), rep(2,6), rep(3,6), rep(4,6), rep(5,6), rep(6,6)))
oper <- as.factor(rep(c(1,1,2,2,3,3), 6))
time <- c(158.3, 159.4, 159.2, 159.6, 158.9, 157.8,
154.6, 154.9, 157.7, 156.8, 154.8, 156.3,
162.5, 162.6, 161.0, 158.9, 160.5, 159.5,
160.0, 158.7, 157.5, 158.9, 161.1, 158.5,
156.3, 158.1, 158.3, 156.9, 157.7, 156.9,
163.7, 161.0, 162.3, 160.3, 162.6, 161.8)
job.d <- data.frame(job, oper, time)
job.m <- lmer(time ~ oper + (1|job:oper), data = job.d)
job.m <- lmer(time ~ (1|job) + (1|job:oper), data = job.d)
job.m.two <- lmer(time ~ (1|job:oper), data = job.d)
anova(job.m, job.m.two)
job.m.three <- lmer(time ~ (1|job), data = job.d)
anova(job.m, job.m.three)
summary(job.m.three)
job.res <- resid(job.m.three)
job.fit <- fitted(job.m.three)
job.res.d <- data.frame(job.res, job.fit)
qqnorm(job.res)
ggplot(job.res.d, aes(x=job.fit, y=job.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
install.packages("roxygen2")
new_post("hey", ext = ".rmd")
library(blogdown)
new_post("hey", ext = ".rmd")
1 + 1
max(c(1, 2))
myvector <- c(1, 2, 3)
max(myvector)
min(myvector)
library(polMod)
library(rnoaa)
library(RSelenium)
user_name <- "glo003@bucknell.edu"
password <- "greyheron36"
query <- "'rawData'"
format <- "'AQCSV'"
param_class <- "'AQI POLLUTANTS'"
param_code <- "44201"
begin_date <- "20160721"
end_date <- "20160722"
state_option <- state.name.to.code("DE")
duration <- "1"
acquire.EPA.state.summary(user_name, password, query, format, param_class, param_code,
begin_date, end_date, state_option, duration)
source('~/TheEconomist.R', echo=TRUE)
library(RSelenium)
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
# Specify the desired download directory
"download.default_directory" = "/Users/Leonard/Desktop/Kennkyuu/getting_epaaqi_data/selenium_idea/downloaded_data"
)
)
)
rD <- rsDriver(extraCapabilities = eCaps)
setwd("~/Desktop/Future/GitHubUploadable/ビデオゲームのデータ")
games <- read.csv( "Video_Game_Sales_Clean.csv" )
names(games)
library(ISLR)
lm.fit = lm(Global_Sales ~ Critic_Score + User_Score, data = games)
lm.fit
summary(lm.fit)
names(lm.fit)
lm.fit = lm(Global_Sales ~ Critic_Score, data = games)
lm.fit
summary(lm.fit)
data()
t.data <- data("trees")
names(t.data)
t.data <- data(trees)
t.data <- data(trees)
names(t.data)
trees
names(trees)
lm.fit <- lm(Volume ~ Girth + Height, data = trees)
lm.fit
summary(lm.fit)
install.packages("ISRL")
install.packages("ISLR")
install.packages("ISLR")
library(ISLR)
install.packages("ISLR")
