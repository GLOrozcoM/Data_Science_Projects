ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
?svydesign
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample <- sample(pop.house.income, samp.size, replace = TRUE)
# Tell R the study design for our sample
my.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=NULL)
# Calculate sample mean and SE
svymean(x=~totinch, design=my.design)
my.mean <- svymean(x=~totinch, design=my.design)[1]
my.SE <- round(SE(svymean(x=~totinch, design=my.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample.rows <- sample(1024, samp.size, replace = TRUE)
new.sample <- statvil[new.sample.rows,]
# Tell R the study design for our sample
my.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=NULL)
# Calculate sample mean and SE
svymean(x=~totinch, design=my.design)
my.mean <- svymean(x=~totinch, design=my.design)[1]
my.SE <- round(SE(svymean(x=~totinch, design=my.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
library(plotrix)
install.packages("plotrix")
library(plotrix)
plot(x=1,y=1, main="Confidence Intervals for Income", xlab="Income", ylab="Sample",
xlim=c(min(lower.conf.ints), max(upper.conf.ints)),
ylim=c(0,55))
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
for(i in 1:50){
plotCI(x=all.means[i], y=i,
ui=upper.conf.ints[i], li=lower.conf.ints[i],
sfrac=0.005, err="x", add=TRUE, cex=0.3)
}
plot(x=1,y=1, main="Confidence Intervals for Income", xlab="Income", ylab="Sample",
xlim=c(min(lower.conf.ints), max(upper.conf.ints)),
ylim=c(0,55))
# Add a reference line for true population mean
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
# Plot 50 confidence intervals
for(i in 1:50){
plotCI(x=all.means[i], y=i,
ui=upper.conf.ints[i], li=lower.conf.ints[i],
sfrac=0.005, err="x", add=TRUE, cex=0.3)
}
library(plotrix)
# Set up an empty plot first, with the relevant limits for x and y axes
plot(x=1,y=1, main="Confidence Intervals for Income", xlab="Income", ylab="Sample",
xlim=c(min(lower.conf.ints), max(upper.conf.ints)),
ylim=c(0,55))
# Add a reference line for true population mean
pop.mean <- mean(statvil$totinch)   # 56780.02
lines(c(pop.mean, pop.mean), c(-5,65))
# Plot 50 confidence intervals
for(i in 1:50){
plotCI(x=all.means[i], y=i,
ui=upper.conf.ints[i], li=lower.conf.ints[i],
sfrac=0.005, err="x", add=TRUE, cex=0.3)
}
```{r}
set.seed(12345)
runs = 50       # Declare the number of repetitions
samp.size <- 80 # Declare the sample size
all.means <- NULL
lower.conf.ints <- NULL
upper.conf.ints <- NULL
for(i in 1:runs ){
# Draw a new sample with replacement
new.sample.rows <- sample(1024, samp.size, replace = TRUE)
new.sample <- statvil[new.sample.rows,]
# Tell R the study design for our sample
new.design <- svydesign(id=~1, strata=NULL, data=new.sample, fpc=NULL, weights = NULL)
# Calculate sample mean and SE
svymean(x=~totinch, design=new.design)
my.mean <- svymean(x=~totinch, design=new.design)[1]
my.SE <- round(SE(svymean(x=~totinch, design=new.design)), 2)
# Calculate mean and save in master list
all.means[i] <- my.mean
# Each confidence interval will require the standard error and the z-quantile
ci.term <- 1.96 * my.SE
# Calculate confidence intervals
# my.conf.ints <-
# Save these in the master list.
lower.conf.ints[i] <- my.mean - ci.term
upper.conf.ints[i] <- my.mean + ci.term
}
curve(expr=dnorm(x, mean=mean(pop.house.income, na.rm = TRUE), sd=sd(pop.house.income, na.rm = TRUE)), from=0, to=4, add=TRUE)
hist(pop.house.income, breaks=50, col="orange", probability=TRUE,
main="Total Population Household Income", xlab="Values")
m <- mean(pop.house.income)
std <- sd(pop.house.income)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(statvil$totinch, breaks=50, col="orange", probability=TRUE,
main="Total Population Household Income", xlab="Values")
m <- mean(pop.house.income)
std <- sd(pop.house.income)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
hist(statvil$totinch, breaks=50, col="orange", probability=TRUE, density = 20,
main="Total Population Household Income", xlab="Values")
m <- mean(pop.house.income)
std <- sd(pop.house.income)
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
curve(dnorm(statvil$totinch, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
curve(dnorm(x, mean=m, sd=std),
col="darkblue", lwd=2, add=TRUE, yaxt="n")
library(polMod)
knitr::opts_chunk$set(echo = TRUE)
proc <- as.factor(rep(c(1,1,1,1, 2,2,2,2, 3,3,3,3), 3))
bat <- as.factor(rep(c(1,2,3,4, 1,2,3,4, 1,2,3,4), 3))
bur <- c(25, 19, 15, 15, 19, 23, 18, 35, 14, 35, 38, 25,
30, 28, 17, 16, 17, 24, 21, 27, 15, 21, 54, 29,
26, 20, 14, 13, 14, 21, 17, 25, 20, 24, 50, 33)
burn.d <- data.frame(proc, bat, bur)
library(lmer)
library(lme4)
library(lmerTest)
burn.m <- lmer(bur ~ proc + (1|bat), data = burn.d)
summary(burn.m)
burn.m.red.one <-  lmer(bur ~ proc, data = burn.d)
burn.m.red.one <-  aov(bur ~ proc, data = burn.d)
anova(burn.m, burn.m.red.one)
anova(burn.m.red.one)
library(agricolae)
burn.Tukey <- HSD.test(burn.m.red.one, "proc", group = TRUE)
burn.T
burn.Tukey
burn.res <- burn.m.red.one$residuals
burn.fit <- burn.m.red.one$fitted.values
qqnorm(burn.res)
burn.res.d <- data.frame(burn.res, burn.fit)
ggplot(burn.res.d, aes(x=burn.fit, y=burn.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
library(ggplot2)
ggplot(burn.res.d, aes(x=burn.fit, y=burn.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(lmerTest)
library(agricolae)
library(ggplot2)
semiconductor <- data.frame(resistance = c(5.22, 	5.6, 	5.78, 	5.57, 	5.66, 	6.23, 	6.75, 	6.12, 	5.61, 	5.91, 	6.52, 	5.96, 	6.25, 	6.84, 	6.97, 	6.61, 	6.11, 	5.49, 	5.9, 	6.43, 	5.46, 	6.22, 	6.02, 	6.05, 	6.33, 	4.6, 	5.67, 	5.81, 	5.08, 	6.29, 	6.88, 	6.15, 	6.13, 	4.95, 	5.77, 	5.83, 	6.53, 	5.63, 	6.22, 	5.55, 	6.14, 	5.42, 	6.23, 	6.12, 	6.5, 	6.36, 	6.54, 	6.13),
et = as.factor(c(1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4, 	1, 	1, 	2, 	2, 	3, 	3, 	4, 	4)),
wafer = as.factor(c(1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	2, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3, 	2, 	3)),
pos = as.factor(c(1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	2, 	4, 	2, 	4, 	2, 	4, 	2, 	4, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	4, 	2, 	4, 	2, 	4, 	2, 	4, 	2, 	1, 	3, 	1, 	3, 	1, 	3, 	1, 	3, 	2, 	4, 	2, 	4, 	2, 	4, 	2, 	4))
)
resistance.m <- lmer(resistance ~ et + pos + (1|et:wafer),data = semiconductor)
summary(resistance.m)
resistance.m.one <- lmer(resistance ~ et + pos, data = semiconductor)
resistance.m.one <- lm(resistance ~ et + pos, data = semiconductor)
anova(resistance.m, resistance.m.one)
anova(resistance.m.one)
et.tukey <- HSD.test(resistance.m.one)
et.tukey <- HSD.test(resistance.m.one, "resistance", group = TRUE)
et.tukey
et.tukey <- HSD.test(resistance.m.one, "et", group = TRUE)
et.tukey
resistance.res <- resistance.m.one$residuals
resistance.fit <- resistance.m.one$fitted.values
resistance.res.d <- data.frame(resistance.res, resistance.fi)
resistance.res.d <- data.frame(resistance.res, resistance.fit)
qqnrom(resistance.res)
qqnorm(resistance.res)
ggplot(resistance.res.d, aes(x=resistance.fit, y=resistance.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
summary(resistance.m)
anova(resistance.m)
resistance.m.one <- lm(resistance ~ et + pos, data = semiconductor)
anova(resistance.m, resistance.m.one)
resistance.m <- lmer(resistance ~ et + pos + (1|et:wafer),data = semiconductor)
resistance.m.one <- lm(resistance ~ et + pos, data = semiconductor)
anova(resistance.m, resistance.m.one)
anova(resistance.m)
pos.tukey <- HSD.test(resistance.m.one, "pos", group = TRUE)
pos.tukey
pos.tukey <- HSD.test(resistance.m, "pos", group = TRUE)
pos.tukey <- HSD.test(resistance.m, "pos", group = TRUE)
resistance.res <- resistance.m$residuals
resistance.fit <- resistance.m$fitted.values
resistance.res <- resid(resistance.m)
resistance.fit <- fitted(resistance.m)
resistance.res.d <- data.frame(resistance.res, resistance.fit)
qqnorm(resistance.res)
lsmeans::lsmeans(resistance.m, pairwise~pos, adjust=c("tukey"))
lsmeans::lsmeans(resistance.m, pairwise~et, adjust=c("tukey"))
lsmeans::lsmeans(resistance.m, pairwise~pos, adjust=c("tukey"))
job <- as.factor(c(rep(1, 6), rep(2,6), rep(3,6), rep(4,6), rep(5,6), rep(6,6)))
oper <- as.factor(rep(c(1,1,2,2,3,3), 6))
time <- c(158.3, 159.4, 159.2, 159.6, 158.9, 157.8,
154.6, 154.9, 157.7, 156.8, 154.8, 156.3,
162.5, 162.6, 161.0, 158.9, 160.5, 159.5,
160.0, 158.7, 157.5, 158.9, 161.1, 158.5,
156.3, 158.1, 158.3, 156.9, 157.7, 156.9,
163.7, 161.0, 162.3, 160.3, 162.6, 161.8)
job.d <- data.frame(job, oper, time)
library(lme4)
library(lmerTest)
library(agricolae)
library(ggplot2)
job.m <- lmer(time ~ oper + (1|oper) + (1|oper:job) , data = job.d)
job.m.two <- lmer(time ~ oper + (1|oper), data = job.d)
job.m <- lmer(time ~ oper + (1|job) + (1|oper:job) , data = job.d)
job.m.two <- lmer(time ~ oper + (1|job), data = job.d)
anova(job.m, job.m.two)
job.m.three <- lm(time ~ oper, data = job.d)
anova(job.m.two, job.m.three)
summary(job.m.two)
anova(job.m.three)
job.res <- resid(job.m.two)
job.fit <- fitted(job.m.two)
job.res.d <- data.frame(job.res, job.fit)
qqnorm(job.res)
ggplot(job.res.d, aes(x=job.fit, y=job.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
mean(job.d$time)
job.m <- lmer(time ~ oper + (1|job:oper), data = job.d)
library(lme4)
library(lme4)
library(lmerTest)
library(agricolae)
library(ggplot2)
job.m <- lmer(time ~ oper + (1|job:oper), data = job.d)
job <- as.factor(c(rep(1, 6), rep(2,6), rep(3,6), rep(4,6), rep(5,6), rep(6,6)))
oper <- as.factor(rep(c(1,1,2,2,3,3), 6))
time <- c(158.3, 159.4, 159.2, 159.6, 158.9, 157.8,
154.6, 154.9, 157.7, 156.8, 154.8, 156.3,
162.5, 162.6, 161.0, 158.9, 160.5, 159.5,
160.0, 158.7, 157.5, 158.9, 161.1, 158.5,
156.3, 158.1, 158.3, 156.9, 157.7, 156.9,
163.7, 161.0, 162.3, 160.3, 162.6, 161.8)
job.d <- data.frame(job, oper, time)
job.m <- lmer(time ~ oper + (1|job:oper), data = job.d)
job.m <- lmer(time ~ (1|job) + (1|job:oper), data = job.d)
job.m.two <- lmer(time ~ (1|job:oper), data = job.d)
anova(job.m, job.m.two)
job.m.three <- lmer(time ~ (1|job), data = job.d)
anova(job.m, job.m.three)
summary(job.m.three)
job.res <- resid(job.m.three)
job.fit <- fitted(job.m.three)
job.res.d <- data.frame(job.res, job.fit)
qqnorm(job.res)
ggplot(job.res.d, aes(x=job.fit, y=job.res)) +
geom_point() +
ggtitle("Plot of residuals vs fitted values") +
ylab("Residuals") +
xlab("Fitted Values") +
theme(plot.title = element_text(hjust = 0.5))
install.packages("roxygen2")
new_post("hey", ext = ".rmd")
library(blogdown)
new_post("hey", ext = ".rmd")
1 + 1
max(c(1, 2))
myvector <- c(1, 2, 3)
max(myvector)
min(myvector)
library(polMod)
library(rnoaa)
library(RSelenium)
user_name <- "glo003@bucknell.edu"
password <- "greyheron36"
query <- "'rawData'"
format <- "'AQCSV'"
param_class <- "'AQI POLLUTANTS'"
param_code <- "44201"
begin_date <- "20160721"
end_date <- "20160722"
state_option <- state.name.to.code("DE")
duration <- "1"
acquire.EPA.state.summary(user_name, password, query, format, param_class, param_code,
begin_date, end_date, state_option, duration)
source('~/TheEconomist.R', echo=TRUE)
library(RSelenium)
eCaps <- list(
chromeOptions =
list(prefs = list(
"profile.default_content_settings.popups" = 0L,
"download.prompt_for_download" = FALSE,
# Specify the desired download directory
"download.default_directory" = "/Users/Leonard/Desktop/Kennkyuu/getting_epaaqi_data/selenium_idea/downloaded_data"
)
)
)
rD <- rsDriver(extraCapabilities = eCaps)
data(teengamb)
install.packages("faraway")
library(faraway)
data("teengamb")
attach(teengamb)
attach(teengamb)
sex
model = lm(gamble ~ sex + status + income + verbal)
model
summary(model)
print(1.79e-05)
model$residuals
max(model$residuals)
which(max(model$residuals))
class(model.residuals)
class(model$residuals)
model$residuals[0]
model$residuals[1]
model$residuals[2]
model$residuals[model$residuals == 0]
model$residuals[model$residuals == max(model$residuals)]
teengamb[24,]
mean(teengamb$gamble)
mean(model$residuals)
median(model$residuals)
names(model$residuals)
model$residuals
model$fitted.values
min(gamble)
cor(model$residuals, model$fitted.values)
cor(model$residuals, income)
-7.24 / 10^17
summary(model)
?teengamb
mean(teengamb[teengamb$sex == 0])
mean(teengamb[which(teengamb$sex == 0)])
mean(teengamb[which(teengamb$sex == 0),])
is.na(teengamb)
install.packages("VIM")
library(VIM)
install.packages("VIM")
library(ISLR)
set.seed(1)
?sample
train = sample(392, 196)
train
unique(train)
length(unique(train))
lm.fit = lm(mpg ∼ horsepower, data = Auto,subset = train)
lm.fit = lm(mpg ∼ horsepower, data = Auto,subset = train)
lm(mpg ∼ horsepower, data = Auto,subset = train)
attach(Auto)
lm(mpg ∼ horsepower, data = Auto, subset = train)
lm.fit=lm(mpg∼horsepower ,data=Auto,subset=train)
lm.fit=lm(mpg~horsepower ,data=Auto,subset=train)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
setwd("~/Desktop/GitDS/Data_Science_Projects/Chess")
games = read.csv("games_new_vars.csv")
set.seed(1)
?sample
train = sample(length(games), size = length(games) * 3/4)
train
length(games)
train = sample(nrow(games), size = nrow(games) * 3/4)
train
train.indices = sample(nrow(games), size = nrow(games) * 3/4)
train.data = games[train.indices]
test.data = games[-train.indices]
?subset
train.data = games[train.indices,]
train.data
head(train.data)
head(train.data[2])
nrow(train.data) + nrow(test.data)
nrow(games)
test.data = games[-train.indices,]
nrow(train.data) + nrow(test.data)
split = sample(nrow(games), 1) / length(games)
nrow(train.data) + nrow(test.data)
split
split = round(sample(nrow(games), 1) / length(games))
split
split = floor(sample(nrow(games), 1) / length(games))
fplit
split
set.seed(2)
split = floor(sample(nrow(games), 1) / length(games))
split
split
split
set.seed(1)
split = floor(sample(nrow(games), 1) / length(games))
split
split = floor(sample(nrow(games), 1) / length(games))
split
set.seed(1)
split = floor(sample(nrow(games), 1) / length(games))
split
set.seed(2)
train.indices = sample(nrow(games), size = nrow(games) * 3/4)
train.data = games[train.indices,]
test.data = games[-train.indices,]
nrow(train.data) + nrow(test.data)
sample(nrow(games), 1) / length(games)
split = floor(sample(nrow(games), 1) / nrow(games))
split
set.seed(1)
split = floor(sample(nrow(games), 1) / nrow(games))
split
split = sample(nrow(games), 1) / nrow(games)
split
split = round(sample(nrow(games), 1) / nrow(games))
split
set.seed(1)
split = round(sample(nrow(games), 1) / nrow(games))
split
split = round(sample(nrow(games), 1) / nrow(games))
split
split = sample(nrow(games), 1) / nrow(games)
split = round(nrow(games) * split)
split
set.seed(1)
split = sample(nrow(games), 1) / nrow(games)
split = round(nrow(games) * split)
split
split = sample(nrow(games), 1) / nrow(games)
split = round(nrow(games) * split)
split
split = sample(nrow(games), 1) / nrow(games)
split = round(nrow(games) * split)
split
split = sample(nrow(games), 1) / nrow(games)
split = round(nrow(games) * split)
split
set.seed(1)
split = sample(nrow(games), 1) / nrow(games)
split = round(nrow(games) * split)
split
train.indices = sample(nrow(games), size = split)
train.data = games[train.indices,]
test.data = games[-train.indices,]
nrow(train.data) + nrow(test.data)
install.packages("caret")
glm(higher_rating_won ~ abs_diff_rating,family = binomial(link='logit'), data = games)
install.packages("boot")
library(boot)
glm.fit = glm(higher_rating_won ~ abs_diff_rating,family = binomial(link='logit'), data = games)
cv.error = cv.glm(games, glm.fit)
cv.error$delta
cv.error = cv.glm(games, glm.fit)
cv.error = cv.glm(games. glm.fit, K = 5)
glm.fit = glm(higher_rating_won ~ abs_diff_rating,family = binomial(link='logit'), data = games)
cv.error = cv.glm(games. glm.fit, K = 5)
cv.error = cv.glm(games, glm.fit, K = 5)
cv.error$delta
cv.error = cv.glm(games, glm.fit, K = 10)
cv.error$delta
boot(games$abs_diff_rating, mean, R=1000)
games$abs_diff_rating
meanFunc <- function(x,i){mean(x[i])}
boot(games$abs_diff_rating, meanFunc, R=1000)
mean(games$abs_diff_rating)
install.packages("tictoc")
tic()
print("Starting")
nrow(train.data) + nrow(test.data)
print("Ending")
toc()
library(tictoc)
tic()
print("Starting")
nrow(train.data) + nrow(test.data)
print("Ending")
toc()
tic()
print("Starting")
nrow(train.data) + nrow(test.data)
print("Ending")
toc()
