{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = pd.read_csv('games_new_vars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will fit a few logistic regression models to predict the probability of a higher rating player winning. \n",
    "Order of business: \n",
    "\n",
    "1) Perform k-fold cross validation (k = 5) for a simple logistic regression. Predictor will be absolute value of difference (abs_diff_rating) \n",
    "in rating, and response will be whether the higher rating won (higher_rating_won). \n",
    "\n",
    "2) Get familiar with the multiple logistic regression code before mass producing in a python file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Empty model\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leonard/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Leonard/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Leonard/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Leonard/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/Leonard/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Perform k-fold cross validation for k = 5\n",
    "kf_five = KFold(n_splits = 5)\n",
    "\n",
    "# We will find the estimated_mse\n",
    "est_err_five = 0\n",
    "for train, test in kf_five.split(games):\n",
    "    \n",
    "    # Create training and test data\n",
    "    train_data = games.iloc[train][['abs_diff_rating', 'higher_rating_won']]\n",
    "    test_data = games.iloc[test][['abs_diff_rating', 'higher_rating_won']]\n",
    "    \n",
    "    # Predictor and response (training)\n",
    "    X_train = DataFrame(train_data.abs_diff_rating)\n",
    "    Y_train = DataFrame(train_data.higher_rating_won)\n",
    "    \n",
    "    # Fit the model\n",
    "    lg.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predictor and response(test)\n",
    "    X_test = DataFrame(test_data.abs_diff_rating)\n",
    "    Y_test = DataFrame(test_data.higher_rating_won)\n",
    "    \n",
    "    # Store the score for the model\n",
    "    est_err_five += lg.score(X_test, Y_test)\n",
    "    \n",
    "# Take the average MSE\n",
    "est_err_five = est_mse_five / 5\n",
    "\n",
    "# TODO Ugly dataConversionWarning, fixed in python file\n",
    "# TODO Not MSE here but the ERR being estimated, fixed in python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62483754172536"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_err_five"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric tells me that the model will properly predict a win or los 62% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I want more! I'm going to try and add two more variables into our logistic regression here. \n",
    "\n",
    "1) White is known to have an advantage (how subtle, you can look up here: TODO) over black by getting to move first. So, I intend to code a white_higher_rated\n",
    "(white higher rating) binary variable. 1 if White had the higher rating 0 otherwise. This may help show how being white or black affects having a higher rating over the other player. \n",
    "\n",
    "2) Number of turns. I hypothesize that longer turned games usually result in more venly matched games, despite the rating. Perhaps by knowing the number of turns made, I can say something about the probability of the higher rated player winning. \n",
    "\n",
    "-> Come in Bayes? Information. Random thought about conditional probabilities here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the white_higher_rated variable\n",
    "# If white had the higher rating, we get a 1, otherwise 1. \n",
    "games['white_higher_rated'] = 0\n",
    "games.loc[games.higher_rating == 'white', 'white_higher_rated'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit a multiple logistic regression model \n",
    "lg_mult = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying out multiple predictors. \n",
    "X = DataFrame(games[['abs_diff_rating', 'higher_rating_coded', 'turns', 'white_higher_rated']])\n",
    "Y = DataFrame(games['higher_rating_won'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Leonard/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_mult.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6358061621298235"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_mult.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, about a percentage point increase in performance. Nice. Not bad. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
